{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:02:24.029749800Z",
     "start_time": "2024-10-29T09:02:23.742583400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Seed for reproducibility\n",
    "SEED = 309\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:02:46.556431100Z",
     "start_time": "2024-10-29T09:02:23.761098500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping blurry image: train_data\\tomato\\tomato_0055.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0136.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0153.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0156.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0157.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0158.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0228.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0241.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0261.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0307.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0399.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0433.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0500.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0666.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0765.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0793.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0820.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0877.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0975.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1052.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1111.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1188.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1205.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1206.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1219.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1257.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1289.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1404.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1568.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1664.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1876.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1909.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1958.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0001.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0004.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0022.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0030.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0033.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0056.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0069.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0074.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0076.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0087.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0127.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0134.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0161.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0202.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0227.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0240.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0257.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0263.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0309.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0333.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0351.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0355.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0362.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0366.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0501.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0536.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0539.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0554.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0572.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0583.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0594.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0627.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0631.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0728.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0747.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0762.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0816.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0863.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0873.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0874.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0876.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0932.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0962.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0968.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0986.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1001.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1004.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1005.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1019.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1020.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1022.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1066.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1068.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1154.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1163.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1334.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1359.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1367.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1394.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1407.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1431.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1445.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1449.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1496.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1531.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1578.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1597.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1623.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1650.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1699.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1772.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1793.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1802.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1808.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1812.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1842.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1846.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1863.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1868.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1894.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1982.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1988.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2065.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2170.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2264.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2286.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2324.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2343.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2344.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0020.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0056.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0057.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0082.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0127.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0186.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0299.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0314.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0338.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0361.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0403.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0477.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0488.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0510.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0559.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0639.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0696.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0706.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0831.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0837.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0857.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0905.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0906.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0926.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0931.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0990.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1041.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1047.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1175.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1242.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1248.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1305.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1331.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1339.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1343.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1518.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1558.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1581.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1680.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1684.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1691.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1718.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1759.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1763.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1781.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1795.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1825.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1840.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1859.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1902.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1915.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1923.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1976.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_2005.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_2009.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_2019.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_2037.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_2081.jpg\n",
      "Preprocessing completed. Processed images are saved in the 'processed_data' folder.\n",
      "Skipped 180 bad images.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dataset paths\n",
    "dataset_path = 'train_data'\n",
    "output_path = 'processed_data'\n",
    "classes = ['tomato', 'cherry', 'strawberry']\n",
    "target_size = (128, 128)\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for cls in classes:\n",
    "    os.makedirs(os.path.join(output_path, cls), exist_ok=True)\n",
    "\n",
    "# Blurry image detection function\n",
    "def is_blurry(image):\n",
    "    gray_image = np.array(image.convert('L'))\n",
    "    laplacian_var = cv2.Laplacian(gray_image, cv2.CV_64F).var()\n",
    "    return laplacian_var > 2000  # Threshold for blurriness\n",
    "\n",
    "count = 0\n",
    "# Preprocess images\n",
    "for fruit_class in classes:\n",
    "    folder_path = os.path.join(dataset_path, fruit_class)\n",
    "    output_folder_path = os.path.join(output_path, fruit_class)\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Check for blur\n",
    "        if is_blurry(image):\n",
    "            print(f\"Skipping blurry image: {image_path}\")\n",
    "            count += 1\n",
    "            continue\n",
    "        \n",
    "        # Resize and save preprocessed image\n",
    "        image = ImageOps.fit(image, target_size, Image.LANCZOS)\n",
    "        processed_image_path = os.path.join(output_folder_path, image_file)\n",
    "        image.save(processed_image_path)\n",
    "\n",
    "print(\"Preprocessing completed. Processed images are saved in the 'processed_data' folder.\")\n",
    "print(f\"Skipped {count} bad images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:02:46.557430900Z",
     "start_time": "2024-10-29T09:02:46.551751300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=(-30, 30)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:02:46.619238500Z",
     "start_time": "2024-10-29T09:02:46.559434500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define data directories\n",
    "data_root = './train_data/'\n",
    "preprocessed_data_root = './processed_data/'\n",
    "\n",
    "# Load datasets with transformations\n",
    "train_dataset = ImageFolder(root=data_root, transform=transform_train)\n",
    "test_dataset = ImageFolder(root=preprocessed_data_root, transform=transform_test)\n",
    "\n",
    "# Split datasets into training and test sets\n",
    "batch_size = 64\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "test_size = len(train_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(train_dataset, [train_size, test_size])\n",
    "\n",
    "# Load data\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:02:46.698335200Z",
     "start_time": "2024-10-29T09:02:46.623238800Z"
    }
   },
   "outputs": [],
   "source": [
    "# MLP Model for baseline comparison\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size=128*128*3, hidden_size=100, num_classes=3):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the image\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize MLP model, criterion, and optimizer\n",
    "mlp_model = MLPModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:04:41.151765Z",
     "start_time": "2024-10-29T09:02:46.702342200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 3.1625\n",
      "Epoch [2/10], Loss: 1.2496\n",
      "Epoch [3/10], Loss: 1.2257\n",
      "Epoch [4/10], Loss: 1.1320\n",
      "Epoch [5/10], Loss: 1.2585\n",
      "Epoch [6/10], Loss: 1.0754\n",
      "Epoch [7/10], Loss: 1.0385\n",
      "Epoch [8/10], Loss: 1.0268\n",
      "Epoch [9/10], Loss: 1.0256\n",
      "Epoch [10/10], Loss: 0.9970\n"
     ]
    }
   ],
   "source": [
    "def train_mlp_model(data_loader):\n",
    "    mlp_model.train()\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = mlp_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(data_loader):.4f}\")\n",
    "\n",
    "# Train MLP model\n",
    "train_mlp_model(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:04:54.550265500Z",
     "start_time": "2024-10-29T09:04:41.156747700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Model Train Accuracy: 53.65%\n",
      "MLP Model Test Accuracy: 51.39%\n"
     ]
    },
    {
     "data": {
      "text/plain": "(53.651059085841695, 51.39353400222966)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_mlp_model(model, train_loader, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    def evaluate(data_loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in data_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        return accuracy\n",
    "    \n",
    "    train_accuracy = evaluate(train_loader)\n",
    "    test_accuracy = evaluate(test_loader)\n",
    "    \n",
    "    print(f'MLP Model Train Accuracy: {train_accuracy:.2f}%')\n",
    "    print(f'MLP Model Test Accuracy: {test_accuracy:.2f}%')\n",
    "    \n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "# Evaluate MLP Model\n",
    "evaluate_mlp_model(mlp_model, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:04:54.633968Z",
     "start_time": "2024-10-29T09:04:54.556373800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CNN Model with dynamic flattened layer size\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(CNN, self).__init__()\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Build CNN model with variable convolutional layers\n",
    "def build_cnn(num_conv_layers):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for i in range(num_conv_layers):\n",
    "        layers.extend([\n",
    "            nn.Conv2d(in_channels, 6 * (2 ** i), kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        ])\n",
    "        in_channels = 6 * (2 ** i)\n",
    "\n",
    "    # Calculate the flattened dimension after convolutional layers\n",
    "    dummy_input = torch.randn(1, 3, 128, 128).to(device)  # Match input image size here\n",
    "    with torch.no_grad():\n",
    "        # Move layers to device (GPU) for dummy calculation\n",
    "        dummy_output = nn.Sequential(*layers).to(device)(dummy_input)\n",
    "    flattened_size = dummy_output.view(-1).shape[0]\n",
    "\n",
    "    # Add fully connected layers\n",
    "    layers.extend([\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(flattened_size, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 3)  # Adjust for number of classes\n",
    "    ])\n",
    "    \n",
    "    return CNN(layers).to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Define train_and_evaluate function\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs=5):\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Initialize models with 1, 2, and 3 convolutional layers\n",
    "models = {\n",
    "    \"1 Conv Layer\": build_cnn(1),\n",
    "    \"2 Conv Layers\": build_cnn(2),\n",
    "    \"3 Conv Layers\": build_cnn(3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:04:54.647392600Z",
     "start_time": "2024-10-29T09:04:54.638968700Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "    # Evaluation on test set\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# Dictionary to store model accuracies\n",
    "accuracies = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "\n",
    "# Define cross-validation function\n",
    "def cross_validate_model(model, train_dataset, folds=3):\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    accuracies = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        val_subset = Subset(train_dataset, val_idx)\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        valloader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Optimizer and criterion\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Train and evaluate\n",
    "        accuracy = train_and_evaluate(model, train_loader, valloader, criterion, optimizer)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    print(f\"Average cross-validated accuracy: {avg_accuracy:.2f}%\")\n",
    "    return avg_accuracy\n",
    "\n",
    "# Test different optimizers\n",
    "def test_optimizers(model, optimizers, train_loader, test_loader, epochs=5):\n",
    "    results = {}\n",
    "    for opt_name, opt_fn in optimizers.items():\n",
    "        model_copy = build_cnn(2)  # Build a new model instance\n",
    "        optimizer = opt_fn(model_copy.parameters())\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        print(f\"\\nTesting optimizer: {opt_name}\")\n",
    "        accuracy = train_and_evaluate(model_copy, train_loader, test_loader, criterion, optimizer, epochs)\n",
    "        results[opt_name] = accuracy\n",
    "    return results\n",
    "\n",
    "# Optimizer configurations\n",
    "optimizers = {\n",
    "    \"SGD\": lambda params: optim.SGD(params, lr=0.001, momentum=0.9),\n",
    "    \"Adam\": lambda params: optim.Adam(params, lr=0.001),\n",
    "    \"RMSProp\": lambda params: optim.RMSprop(params, lr=0.001)\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T09:04:54.658743100Z",
     "start_time": "2024-10-29T09:04:54.644391800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: 1 Conv Layer\n",
      "Epoch [1/5], Loss: 1.1422\n",
      "Epoch [2/5], Loss: 1.0078\n",
      "Epoch [3/5], Loss: 0.9949\n",
      "Epoch [4/5], Loss: 0.9791\n",
      "Epoch [5/5], Loss: 0.9434\n",
      "Accuracy on test set: 53.29%\n",
      "\n",
      "Training model: 2 Conv Layers\n",
      "Epoch [1/5], Loss: 1.1228\n"
     ]
    }
   ],
   "source": [
    "# Initialize accuracies dictionary to store model accuracies\n",
    "accuracies = {}\n",
    "\n",
    "# Training and recording each model's accuracy\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining model: {model_name}\")\n",
    "    accuracy = train_and_evaluate(model, train_loader, test_loader, nn.CrossEntropyLoss(), optim.Adam(model.parameters()))\n",
    "    accuracies[model_name] = accuracy\n",
    "\n",
    "# Cross-validation\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nCross-validating model: {model_name}\")\n",
    "    avg_accuracy = cross_validate_model(model, train_dataset)\n",
    "    accuracies[f\"{model_name} (CV)\"] = avg_accuracy\n",
    "\n",
    "# Test different optimizers\n",
    "optimizer_results = test_optimizers(build_cnn(2), optimizers, train_loader, test_loader)\n",
    "accuracies.update(optimizer_results)\n",
    "\n",
    "# Display collected accuracies\n",
    "print(\"\\nModel Accuracies:\")\n",
    "for model, acc in accuracies.items():\n",
    "    print(f\"{model}: {acc:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-10-29T09:04:54.661748300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %%\n",
    "# Plotting results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(list(accuracies.keys()), list(accuracies.values()))\n",
    "plt.xlabel(\"Accuracy (%)\")\n",
    "plt.ylabel(\"Model Configuration\")\n",
    "plt.title(\"Model Comparison with Varying Parameters and Optimizers\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %%\n",
    "model_resnet = resnet50(weights=\"IMAGENET1K_V2\")\n",
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Modify the last layer to output 3 classes\n",
    "num_features = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(num_features, 3)\n",
    "model_resnet = model_resnet.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnet.parameters(), lr=0.001)\n",
    "\n",
    "# Train and evaluate transfer learning model\n",
    "print(\"\\nTraining Transfer Learning Model (ResNet-50):\")\n",
    "transfer_learning_accuracy = train_and_evaluate(model_resnet, train_loader, test_loader, criterion, optimizer, epochs=10)\n",
    "accuracies[\"Transfer Learning (ResNet-50)\"] = transfer_learning_accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Update train_and_evaluate to track both training and test accuracy per epoch\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs=10):\n",
    "    model.to(device)\n",
    "    train_accuracies = []  # Store training accuracy for each epoch\n",
    "    test_accuracies = []   # Store test accuracy for each epoch\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate training accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate and store training accuracy\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # Calculate test accuracy\n",
    "        model.eval()\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate and store test accuracy\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    return train_accuracies, test_accuracies\n",
    "\n",
    "# Initialize and train the model while tracking accuracies\n",
    "print(\"\\nTraining Transfer Learning Model (ResNet-50):\")\n",
    "train_accuracies, test_accuracies = train_and_evaluate(model_resnet, train_loader, test_loader, criterion, optimizer, epochs=10)\n",
    "\n",
    "# Plotting train and test accuracy over epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), train_accuracies, marker='o', label='Train Accuracy')\n",
    "plt.plot(range(1, 11), test_accuracies, marker='o', label='Test Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Train and Test Accuracy per Epoch for Transfer Learning (ResNet-50)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs=10):\n",
    "    model.to(device)\n",
    "    train_accuracies = []  # Store training accuracy for each epoch\n",
    "    test_accuracies = []   # Store test accuracy for each epoch\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate training accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate and store training accuracy\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # Calculate test accuracy\n",
    "        model.eval()\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate and store test accuracy\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    return train_accuracies, test_accuracies\n",
    "\n",
    "# Initialize and train the model while tracking accuracies\n",
    "print(\"\\nTraining Transfer Learning Model (ResNet-50):\")\n",
    "train_accuracies, test_accuracies = train_and_evaluate(model_resnet, train_loader, test_loader, criterion, optimizer, epochs=10)\n",
    "\n",
    "# Plotting train and test accuracy over epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), train_accuracies, marker='o', label='Train Accuracy')\n",
    "plt.plot(range(1, 11), test_accuracies, marker='o', label='Test Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Train and Test Accuracy per Epoch for Transfer Learning (ResNet-50)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "# Load dataset and split into training and testing sets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_dir = \"train_data\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Load ResNet-50 model with pretrained weights and modify the final layer\n",
    "CNN = models.resnet50(weights=\"IMAGENET1K_V2\")  # Use pre-trained weights\n",
    "CNN.fc = nn.Linear(CNN.fc.in_features, 3)  # Adjust final layer for 3 classes\n",
    "CNN = CNN.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(CNN.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)  # Reduce LR every 7 epochs\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 10\n",
    "train_losses, test_losses = [], []\n",
    "train_accuracies, test_accuracies = [], []\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_losses.append(train_loss / total)\n",
    "        train_accuracies.append(correct / total)\n",
    "\n",
    "        # Testing phase\n",
    "        model.eval()\n",
    "        test_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                test_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        test_losses.append(test_loss / total)\n",
    "        test_accuracies.append(correct / total)\n",
    "\n",
    "        scheduler.step()  # Update learning rate\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracies[-1]:.4f}, '\n",
    "              f'Test Loss: {test_losses[-1]:.4f}, Test Accuracy: {test_accuracies[-1]:.4f}, '\n",
    "              f'Time: {elapsed_time:.2f}s')\n",
    "\n",
    "# Train and evaluate\n",
    "train_and_evaluate(CNN, criterion, optimizer, scheduler, num_epochs)\n",
    "\n",
    "# Plotting\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss', marker='o')\n",
    "plt.plot(epochs, test_losses, label='Testing Loss', marker='x')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epochs)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy', marker='o')\n",
    "plt.plot(epochs, test_accuracies, label='Testing Accuracy', marker='x')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(epochs)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Add this line at the top\n",
    "\n",
    "# Training and evaluation function with tqdm progress bar\n",
    "def train_and_evaluate(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "        \n",
    "        # Wrap train_loader with tqdm for progress display\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_losses.append(train_loss / total)\n",
    "        train_accuracies.append(correct / total)\n",
    "\n",
    "        # Testing phase\n",
    "        model.eval()\n",
    "        test_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        # Wrap test_loader with tqdm for progress display\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Testing\", leave=False):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                test_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        test_losses.append(test_loss / total)\n",
    "        test_accuracies.append(correct / total)\n",
    "\n",
    "        scheduler.step()  # Update learning rate\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracies[-1]:.4f}, '\n",
    "              f'Test Loss: {test_losses[-1]:.4f}, Test Accuracy: {test_accuracies[-1]:.4f}, '\n",
    "              f'Time: {elapsed_time:.2f}s')\n",
    "\n",
    "# Train and evaluate with tqdm progress bar\n",
    "train_and_evaluate(model_resnet, criterion, optimizer, scheduler, num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
