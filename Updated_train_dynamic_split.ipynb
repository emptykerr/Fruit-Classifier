{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Seed for reproducibility\n",
    "SEED = 309\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "25e9f392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping blurry image: train_data\\tomato\\tomato_0055.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0136.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0153.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0156.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0157.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0158.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0228.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0241.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0261.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0307.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0399.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0433.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0500.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0666.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0765.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0793.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0820.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0877.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_0975.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1052.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1111.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1188.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1205.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1206.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1219.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1257.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1289.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1404.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1568.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1664.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1876.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1909.jpg\n",
      "Skipping blurry image: train_data\\tomato\\tomato_1958.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0001.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0004.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0022.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0030.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0033.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0056.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0069.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0074.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0076.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0087.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0127.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0134.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0161.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0202.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0227.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0240.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0257.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0263.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0309.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0333.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0351.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0355.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0362.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0366.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0501.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0536.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0539.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0554.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0572.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0583.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0594.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0627.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0631.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0728.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0747.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0762.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0816.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0863.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0873.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0874.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0876.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0932.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0962.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0968.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_0986.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1001.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1004.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1005.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1019.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1020.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1022.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1066.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1068.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1154.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1163.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1334.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1359.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1367.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1394.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1407.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1431.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1445.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1449.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1496.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1531.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1578.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1597.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1623.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1650.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1699.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1772.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1793.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1802.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1808.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1812.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1842.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1846.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1863.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1868.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1894.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1982.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_1988.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2065.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2170.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2264.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2286.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2324.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2343.jpg\n",
      "Skipping blurry image: train_data\\cherry\\cherry_2344.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0020.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0056.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0057.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0082.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0127.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0186.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0299.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0314.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0338.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0361.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0403.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0477.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0488.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0510.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0559.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0639.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0696.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0706.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0831.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0837.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0857.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0905.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0906.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0926.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0931.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_0990.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1041.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1047.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1175.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1242.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1248.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1305.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1331.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1339.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1343.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1518.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1558.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1581.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1680.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1684.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1691.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1718.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1759.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1763.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1781.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1795.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1825.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1840.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1859.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1902.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1915.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1923.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_1976.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_2005.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_2009.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_2019.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_2037.jpg\n",
      "Skipping blurry image: train_data\\strawberry\\strawberry_2081.jpg\n",
      "Preprocessing completed. Processed images are saved in the 'processed_data' folder.\n"
     ]
    }
   ],
   "source": [
    "# Dataset paths\n",
    "dataset_path = 'train_data'\n",
    "output_path = 'processed_data'\n",
    "classes = ['tomato', 'cherry', 'strawberry']\n",
    "target_size = (128, 128)\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for cls in classes:\n",
    "    os.makedirs(os.path.join(output_path, cls), exist_ok=True)\n",
    "\n",
    "# Blurry image detection function\n",
    "def is_blurry(image):\n",
    "    gray_image = np.array(image.convert('L'))\n",
    "    laplacian_var = cv2.Laplacian(gray_image, cv2.CV_64F).var()\n",
    "    return laplacian_var > 2000  # Threshold for blurriness\n",
    "\n",
    "# Preprocess images\n",
    "for fruit_class in classes:\n",
    "    folder_path = os.path.join(dataset_path, fruit_class)\n",
    "    output_folder_path = os.path.join(output_path, fruit_class)\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Check for blur\n",
    "        if is_blurry(image):\n",
    "            print(f\"Skipping blurry image: {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Resize and save preprocessed image\n",
    "        image = ImageOps.fit(image, target_size, Image.LANCZOS)\n",
    "        processed_image_path = os.path.join(output_folder_path, image_file)\n",
    "        image.save(processed_image_path)\n",
    "\n",
    "print(\"Preprocessing completed. Processed images are saved in the 'processed_data' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c505c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(target_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directories\n",
    "data_root = './train_data/'\n",
    "preprocessed_data_root = './processed_data/'\n",
    "\n",
    "# Load datasets with transformations\n",
    "train_dataset = ImageFolder(root=data_root, transform=transform_train)\n",
    "test_dataset = ImageFolder(root=preprocessed_data_root, transform=transform_test)\n",
    "\n",
    "# Split datasets into training and test sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "test_size = len(train_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(train_dataset, [train_size, test_size])\n",
    "\n",
    "# Load data\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Model for baseline comparison\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size=128*128*3, hidden_size=100, num_classes=3):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the image\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize MLP model, criterion, and optimizer\n",
    "mlp_model = MLPModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.5784\n",
      "Epoch [2/10], Loss: 1.2750\n",
      "Epoch [3/10], Loss: 1.1492\n",
      "Epoch [4/10], Loss: 1.0948\n",
      "Epoch [5/10], Loss: 1.0803\n",
      "Epoch [6/10], Loss: 1.0199\n",
      "Epoch [7/10], Loss: 1.0288\n",
      "Epoch [8/10], Loss: 0.9715\n",
      "Epoch [9/10], Loss: 0.9560\n",
      "Epoch [10/10], Loss: 0.9734\n"
     ]
    }
   ],
   "source": [
    "def train_mlp_model(data_loader):\n",
    "    mlp_model.train()\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = mlp_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(data_loader):.4f}\")\n",
    "\n",
    "# Train MLP model\n",
    "train_mlp_model(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Model Train Accuracy: 57.22%\n",
      "MLP Model Test Accuracy: 50.28%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57.21850613154961, 50.27870680044593)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_mlp_model(model, train_loader, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    def evaluate(data_loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in data_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        return accuracy\n",
    "    \n",
    "    train_accuracy = evaluate(train_loader)\n",
    "    test_accuracy = evaluate(test_loader)\n",
    "    \n",
    "    print(f'MLP Model Train Accuracy: {train_accuracy:.2f}%')\n",
    "    print(f'MLP Model Test Accuracy: {test_accuracy:.2f}%')\n",
    "    \n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "# Evaluate MLP Model\n",
    "evaluate_mlp_model(mlp_model, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 3)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 16 * 16)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize CNN model\n",
    "cnn_model = CNNModel().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1001\n",
      "Epoch [2/10], Loss: 1.1000\n",
      "Epoch [3/10], Loss: 1.0997\n",
      "Epoch [4/10], Loss: 1.1001\n",
      "Epoch [5/10], Loss: 1.1000\n",
      "Epoch [6/10], Loss: 1.0997\n",
      "Epoch [7/10], Loss: 1.1003\n",
      "Epoch [8/10], Loss: 1.0996\n",
      "Epoch [9/10], Loss: 1.0997\n",
      "Epoch [10/10], Loss: 1.1002\n",
      "CNN Model Accuracy: 36.34%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36.34336677814939"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training function for CNN\n",
    "def train_cnn_model(data_loader):\n",
    "    cnn_model.train()\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = cnn_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(data_loader):.4f}\")\n",
    "\n",
    "# Evaluation function for CNN\n",
    "def evaluate_cnn_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'CNN Model Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# Train and evaluate CNN model\n",
    "train_cnn_model(train_loader)\n",
    "evaluate_cnn_model(cnn_model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
